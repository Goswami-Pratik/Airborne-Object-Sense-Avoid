{"cells":[{"cell_type":"markdown","id":"5bfdf956","metadata":{"id":"5bfdf956"},"source":["# Setting Up"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-Gf_LUs5v0g","executionInfo":{"status":"ok","timestamp":1648625962498,"user_tz":-60,"elapsed":21009,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"outputId":"d3555361-35d5-45e2-e26b-9d82d3e633a7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"id":"y-Gf_LUs5v0g"},{"cell_type":"code","source":["!pip install loguru coloredlogs matplotlib pandas loguru boto3 opencv-python bounding-box numpy Pillow imgaug\n","\n","!pip install matplotlib numpy opencv-python Pillow PyYAML requests scipy torch torchvision tqdm tensorboard pandas seaborn thop"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKotEft_ikRR","executionInfo":{"status":"ok","timestamp":1648625978115,"user_tz":-60,"elapsed":15628,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"outputId":"999b1bda-9ee8-4ccc-90f9-e5c7dd5ad5a9"},"id":"nKotEft_ikRR","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting loguru\n","  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n","\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 30 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 51 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 4.4 MB/s \n","\u001b[?25hCollecting coloredlogs\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[?25l\r\u001b[K     |███████▏                        | 10 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 20 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 30 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 40 kB 36.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Collecting boto3\n","  Downloading boto3-1.21.29-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 15.4 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Collecting bounding-box\n","  Downloading bounding_box-0.1.3.tar.gz (164 kB)\n","\u001b[K     |████████████████████████████████| 164 kB 38.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (0.2.9)\n","Collecting humanfriendly>=9.1\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.9 MB/s \n","\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (3.10.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Collecting botocore<1.25.0,>=1.24.29\n","  Downloading botocore-1.24.29-py3-none-any.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 44.9 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.7 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 52.6 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.4.1)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.8.1.post1)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug) (0.18.3)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug) (1.3.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug) (2.6.3)\n","Building wheels for collected packages: bounding-box\n","  Building wheel for bounding-box (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bounding-box: filename=bounding_box-0.1.3-py3-none-any.whl size=163935 sha256=9ded6405778e37e702b8fd6a974d15e4f28937e1f5c4e98dda6c7eef2e5a6eb1\n","  Stored in directory: /root/.cache/pip/wheels/ac/43/da/4b01c5ebbd32a9814495d2cc81e07c95e13aa210aa3cd860b0\n","Successfully built bounding-box\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, humanfriendly, loguru, coloredlogs, bounding-box, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.21.29 botocore-1.24.29 bounding-box-0.1.3 coloredlogs-15.0.1 humanfriendly-10.0 jmespath-1.0.0 loguru-0.6.0 s3transfer-0.5.2 urllib3-1.26.9\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (3.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n","Collecting thop\n","  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (3.10.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 12.7 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.44.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Installing collected packages: urllib3, thop\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.9\n","    Uninstalling urllib3-1.26.9:\n","      Successfully uninstalled urllib3-1.26.9\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed thop-0.0.31.post2005241907 urllib3-1.25.11\n"]}]},{"cell_type":"code","execution_count":4,"id":"aecf05a3","metadata":{"scrolled":true,"id":"aecf05a3","executionInfo":{"status":"ok","timestamp":1648626028201,"user_tz":-60,"elapsed":1182,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}}},"outputs":[],"source":["import json\n","import random\n","import os, sys\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"]=25,25\n","from random import randrange, choice\n","from IPython.display import display, clear_output, HTML\n","from loguru import logger\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n","\n","#homeDir = \"D:\\\\FYP\\\\\"\n","#homeDir = \"A:\\\\University\\\\Final-Year-Project-AI\\\\\"\n","homeDir = \"/content/drive/MyDrive/Final-Year-Project-AI/\""]},{"cell_type":"code","execution_count":6,"id":"e9152946","metadata":{"scrolled":true,"id":"e9152946","executionInfo":{"status":"ok","timestamp":1648626046389,"user_tz":-60,"elapsed":9957,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}}},"outputs":[],"source":["sys.path.append(os.path.dirname(os.path.realpath(os.getcwd())))\n","sys.path.append(os.path.dirname(os.path.realpath(os.getcwd())) + \"/core\")\n","\n","os.chdir(homeDir + \"object-sense-avoid-ai/core/\")\n","# Install the required package\n","!pip install -r ../requirements.txt\n","\n","from core.dataset import Dataset \n","\n","# Clearing the output\n","clear_output()"]},{"cell_type":"code","execution_count":7,"id":"14db4777","metadata":{"scrolled":true,"id":"14db4777","executionInfo":{"status":"ok","timestamp":1648626095201,"user_tz":-60,"elapsed":48818,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a9d61f9f-ec80-4ef1-cfe7-e3bf580e2828"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset(num_flights=1698)\n"]}],"source":["from core.helper import initialise, load_data\n","\n","# Initialize the enviroment\n","initialise(42)\n","\n","os.chdir(homeDir + \"object-sense-avoid-ai/notebooks/\")\n","\n","print(os.getcwd())\n","#dataset = load_data()\n","notebook_path = os.path.dirname(os.path.realpath(\"__file__\")) + \"/data\"\n","local_path = notebook_path + '/part1'\n","s3_path = 's3://airborne-obj-detection-challenge-training/part1/'\n","dataset = Dataset(local_path, s3_path, partial=True, prefix=\"part1\")\n","local_path = notebook_path + '/part2'\n","s3_path = 's3://airborne-obj-detection-challenge-training/part2/'\n","dataset.add(local_path, s3_path, prefix=\"part2\")\n","clear_output()\n","\n","# Print out the dataset\n","print(dataset)"]},{"cell_type":"markdown","id":"d6325dcf","metadata":{"id":"d6325dcf"},"source":["## Create Training Dataset for Yolo models"]},{"cell_type":"code","execution_count":8,"id":"798d1c27","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"798d1c27","executionInfo":{"status":"ok","timestamp":1648626107072,"user_tz":-60,"elapsed":11895,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"outputId":"347b6b30-40bc-42fa-af84-d280e236b279"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setup complete. Using torch 1.10.0+cu111 (Tesla K80)\n"]}],"source":["# Warning: Clone only if base YOLOv5 repo isnt downloaded (in notebooks folder)\n","# !git clone https://github.com/ultralytics/yolov5\n","# os.chdir(\"yolov5\")\n","\n","os.chdir(homeDir + \"object-sense-avoid-ai/notebooks/yolov5\")\n","\n","# Install the required dependences\n","%pip install -r requirements.txt\n","\n","# Import Pytorch\n","import torch\n","from IPython.display import Image, clear_output\n","\n","# Clear output console\n","clear_output()\n","\n","# Print out the working enviroment\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"]},{"cell_type":"code","execution_count":9,"id":"ad784a7a","metadata":{"scrolled":true,"id":"ad784a7a","executionInfo":{"status":"ok","timestamp":1648626107073,"user_tz":-60,"elapsed":26,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"10b0a13e-16fa-417c-9ec2-52f214cd0ba0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5\n"]}],"source":["print(os.getcwd())\n","\n","os.chdir(homeDir + \"object-sense-avoid-ai/data\")\n","\n","flightBatchSize = 0;\n","flight_ids = dataset.get_flight_ids()\n","# while flightBatchSize < 50:\n","#     #for flight in flight_ids:\n","#     currentFlight = dataset.get_flight(flight_ids[flightBatchSize])\n","#     if currentFlight.num_airborne_objs >= 2:\n","#       logger.info(\"Downloading Flight {}: {}\", flightBatchSize, currentFlight)\n","#       currentFlight.download()\n","#     flightBatchSize += 1\n"]},{"cell_type":"code","execution_count":null,"id":"65732a08","metadata":{"scrolled":false,"id":"65732a08","executionInfo":{"status":"ok","timestamp":1644506905367,"user_tz":0,"elapsed":66690,"user":{"displayName":"Pratikgiri Goswami","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-IHdzfDW9q5vpHRDnZ3Wm7c4oMkfMa-KSwAOatQ=s64","userId":"09564737531169887586"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bccd7232-db6f-4d8b-ed62-bbcfeb488b7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iterating through ./notebooks/data/part1/Images/\n","Generating train.txt\n","Generating test.txt\n","Generating original_paths.txt\n","Finish Generating !!! Total of 1330 images and 2959 objects\n"]}],"source":["# os.chdir(homeDir + \"object-sense-avoid-ai/core\")\n","# from core.yolo_data import Yolo_Data\n","# os.chdir(homeDir + \"object-sense-avoid-ai/notebooks/yolov5/data\")\n","\n","# # Create an instance\n","# yolo_data = Yolo_Data()\n","# # Generate training datas and labels\n","# yolo_data.generate_data(dataset)"]},{"cell_type":"code","execution_count":null,"id":"8f24ee4c","metadata":{"id":"8f24ee4c"},"outputs":[],"source":["# os.chdir(homeDir + \"object-sense-avoid-ai\\\\notebooks\\\\yolov5\\\\data\")\n","# if not os.path.exists(\"object-sense-avoid-ai/notebooks/yolov5/data/obj\"):\n","#     open(homeDir + \"object-sense-avoid-ai/notebooks/yolov5/data/obj\", 'a').close()"]},{"cell_type":"code","execution_count":19,"id":"b09e63af","metadata":{"id":"b09e63af","executionInfo":{"status":"ok","timestamp":1648626360864,"user_tz":-60,"elapsed":3,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}}},"outputs":[],"source":["os.chdir(homeDir + \"object-sense-avoid-ai/notebooks/yolov5/data\")"]},{"cell_type":"code","execution_count":20,"id":"294f6cd2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"294f6cd2","executionInfo":{"status":"ok","timestamp":1648626362337,"user_tz":-60,"elapsed":2,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"outputId":"fdf55d5f-ee41-4c83-a961-7fe326e64e50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting aot.yaml\n"]}],"source":["%%file aot.yaml\n","path: \n","train: train.txt\n","val: test.txt\n","test: test.txt\n","nc: 3\n","names: ['Airplane', 'Helicopter', 'Airborne']"]},{"cell_type":"code","execution_count":null,"id":"ba521de0","metadata":{"id":"ba521de0"},"outputs":[],"source":["# %%file aot.yaml\n","# path: D:/FYP/object-sense-avoid-ai/notebooks/yolov5/data/\n","# train: train.txt\n","# val: train.txt\n","# test: test.txt\n","# nc: 6\n","# names: ['Airplane', 'Helicopter', 'Drone', 'Airborne', 'Flock', 'Bird']"]},{"cell_type":"markdown","id":"ccb13dda","metadata":{"id":"ccb13dda"},"source":["## Selecting a model & training model on AOT Dataset"]},{"cell_type":"code","execution_count":11,"id":"09f88bea","metadata":{"id":"09f88bea","executionInfo":{"status":"ok","timestamp":1648626118186,"user_tz":-60,"elapsed":11132,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}}},"outputs":[],"source":["# https://wandb.ai\n","# Install wandb\n","!pip install wandb\n","# Clear the output\n","clear_output()"]},{"cell_type":"code","source":["#01d19932ed834c82bc20737a8f396c1d6649a108\n","!wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWerqVUxkiGh","executionInfo":{"status":"ok","timestamp":1648626125978,"user_tz":-60,"elapsed":7811,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"outputId":"04d8a409-e853-4578-d315-53c75cdfe04e"},"id":"AWerqVUxkiGh","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","execution_count":null,"id":"0985b40d","metadata":{"scrolled":true,"id":"0985b40d"},"outputs":[],"source":["# http://localhost:6006/\n","# Tensorboard (optional)\n","%load_ext tensorboard\n","# Access the training directory\n","%tensorboard --logdir runs/train"]},{"cell_type":"code","execution_count":null,"id":"f86818bd","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"f86818bd","outputId":"7eac7445-3624-4f4e-befb-e44fbc41a1b1","executionInfo":{"status":"ok","timestamp":1645377838902,"user_tz":0,"elapsed":6924011,"user":{"displayName":"Pratikgiri Goswami","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-IHdzfDW9q5vpHRDnZ3Wm7c4oMkfMa-KSwAOatQ=s64","userId":"09564737531169887586"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpgosw\u001b[0m (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp12/weights/best.pt, cfg=, data=aot.yaml, hyp=../data/hyps/hyp.scratch.yaml, epochs=10, batch_size=8, imgsz=1600, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n","YOLOv5 🚀 8b9537a torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlaced-star-48\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pgosw/train\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pgosw/train/runs/1ucha8tx\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/data/wandb/run-20220220_152851-1ucha8tx\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n","\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs\n","\n","Transferred 349/349 items from /content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp12/weights/best.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'train.cache' images and labels... 1064 found, 0 missing, 0 empty, 0 corrupt: 100% 1064/1064 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'train.cache' images and labels... 1064 found, 0 missing, 0 empty, 0 corrupt: 100% 1064/1064 [00:00<?, ?it/s]\n","Plotting labels to ../runs/train/exp13/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.46 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Image sizes 1600 train, 1600 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m../runs/train/exp13\u001b[0m\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       0/9      9.5G   0.02068  0.003545 0.0002281        25      1600: 100% 133/133 [08:07<00:00,  3.67s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:41<00:00,  2.40s/it]\n","                 all       1064       2427      0.806      0.731       0.75      0.464\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       1/9     10.7G   0.02069  0.003448 0.0002085        12      1600: 100% 133/133 [08:09<00:00,  3.68s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:42<00:00,  2.42s/it]\n","                 all       1064       2427      0.789      0.732      0.743      0.458\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       2/9     10.7G   0.02234  0.003669  0.000236        28      1600: 100% 133/133 [08:10<00:00,  3.69s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:44<00:00,  2.46s/it]\n","                 all       1064       2427        0.8      0.726      0.737      0.452\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       3/9     10.7G   0.02369  0.003534  0.000268        18      1600: 100% 133/133 [08:16<00:00,  3.74s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:44<00:00,  2.46s/it]\n","                 all       1064       2427       0.78      0.694      0.712      0.431\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       4/9     10.7G   0.02375  0.003733 0.0003012        28      1600: 100% 133/133 [08:17<00:00,  3.74s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:45<00:00,  2.47s/it]\n","                 all       1064       2427       0.81      0.724      0.746      0.448\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       5/9     10.7G   0.02301  0.003778 0.0003345        27      1600: 100% 133/133 [08:18<00:00,  3.75s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:43<00:00,  2.44s/it]\n","                 all       1064       2427      0.788      0.745      0.755      0.469\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       6/9     10.7G   0.02043  0.003703 0.0002939        18      1600: 100% 133/133 [08:14<00:00,  3.72s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:45<00:00,  2.47s/it]\n","                 all       1064       2427      0.793      0.724      0.738      0.457\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       7/9     10.7G   0.02076  0.003832 0.0003282        21      1600: 100% 133/133 [08:15<00:00,  3.72s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:44<00:00,  2.46s/it]\n","                 all       1064       2427      0.795      0.632      0.675      0.411\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       8/9     10.7G   0.02061  0.003685   0.00031        21      1600: 100% 133/133 [08:18<00:00,  3.75s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:43<00:00,  2.45s/it]\n","                 all       1064       2427      0.806      0.713      0.741      0.455\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       9/9     10.7G   0.02012  0.003702 0.0002898        23      1600: 100% 133/133 [08:21<00:00,  3.77s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:43<00:00,  2.44s/it]\n","                 all       1064       2427      0.771      0.679      0.711      0.441\n","\n","10 epochs completed in 1.849 hours.\n","Optimizer stripped from ../runs/train/exp13/weights/last.pt, 15.3MB\n","Optimizer stripped from ../runs/train/exp13/weights/best.pt, 15.3MB\n","\n","Validating ../runs/train/exp13/weights/best.pt...\n","Fusing layers... \n","Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 67/67 [02:57<00:00,  2.64s/it]\n","                 all       1064       2427      0.787      0.745      0.755      0.469\n","            Airplane       1064        296        0.8      0.733      0.753      0.485\n","          Helicopter       1064       1027      0.975      0.968      0.984      0.681\n","            Airborne       1064       1104      0.586      0.535      0.527       0.24\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 2479... (success).\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 █▇▆▄▇█▇▁▇▄█\n","\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▇▇▆▃▅█▇▁▆▅█\n","\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▇▄▆▃█▄▅▅▇▁▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▇▇▇▅▇█▇▁▆▄█\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss ▂▂▅██▇▂▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss ▂▁▃▄▆█▆█▇▆\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ▃▁▅▃▆▇▆█▅▆\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss ▂▃▂█▄▃▂▄▂▁▃\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss ▁▁▂▂▄▄▄█▃▄▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss ▁▁▁▃▂▂▂█▁▅▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▄▆▇██▆▄▄▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▄▆▇██▆▄▄▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▇▆▅▄▃▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:             best/epoch 5\n","\u001b[34m\u001b[1mwandb\u001b[0m:           best/mAP_0.5 0.75465\n","\u001b[34m\u001b[1mwandb\u001b[0m:      best/mAP_0.5:0.95 0.46918\n","\u001b[34m\u001b[1mwandb\u001b[0m:         best/precision 0.78807\n","\u001b[34m\u001b[1mwandb\u001b[0m:            best/recall 0.74485\n","\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.75476\n","\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.46893\n","\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.78701\n","\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.74547\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.02012\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.00029\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.0037\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.01915\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.00024\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.0036\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00186\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00186\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.00186\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlaced-star-48\u001b[0m: \u001b[34mhttps://wandb.ai/pgosw/train/runs/1ucha8tx\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220220_152851-1ucha8tx/logs/debug.log\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","Results saved to \u001b[1m../runs/train/exp13\u001b[0m\n"]}],"source":["os.chdir(homeDir + \"object-sense-avoid-ai/notebooks/yolov5/data\")\n","!python ../train.py --img 1600 --batch 8 --epochs 10 --data aot.yaml --weights /content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp12/weights/best.pt"]},{"cell_type":"code","source":["# Load our model\n","model = torch.hub.load('./', 'custom', path='./runs/train/exp9/weights/best.pt', source='local')\n","# Cleaning the output\n","clear_output()\n","# Image Path\n","img = '/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/testImages/15553341149037764548af6dc9c2d794ea683e9554a0e728ca3.png'\n","# Inference\n","results = model(img)"],"metadata":{"id":"8eOkcLlh5sxI","colab":{"base_uri":"https://localhost:8080/","height":294},"executionInfo":{"status":"error","timestamp":1648626156221,"user_tz":-60,"elapsed":498,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"outputId":"70366745-0d3c-4801-8992-2c44c8afdc07"},"id":"8eOkcLlh5sxI","execution_count":14,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-a20034724c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'custom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./runs/train/exp9/weights/best.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'local'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Cleaning the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Image Path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mrepo_or_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_cache_or_reload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mhubconf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m     \u001b[0mhub_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhubconf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './hubconf.py'"]}]},{"cell_type":"code","source":["# Print out the prediction\n","results.print()  \n","# results.save()  \n","\n","# Return the Tensorflow format\n","results.xyxy[0]\n","\n","# Show the labeled image\n","results.show()\n","\n","# Return the prediction dataframe\n","results.pandas().xyxy[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"Q7sDJoaV697e","executionInfo":{"status":"ok","timestamp":1644426142048,"user_tz":0,"elapsed":230,"user":{"displayName":"Pratikgiri Goswami","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-IHdzfDW9q5vpHRDnZ3Wm7c4oMkfMa-KSwAOatQ=s64","userId":"09564737531169887586"}},"outputId":"1865a881-ca0c-489c-e37c-71feba567f3f"},"id":"Q7sDJoaV697e","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["image 1/1: 2048x2448 1 Airplane, 1 Helicopter\n","Speed: 118.5ms pre-process, 32.1ms inference, 2.3ms NMS per image at shape (1, 3, 544, 640)\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f439de1c-f8c3-4f6c-9941-8e4a4b1f365e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","      <th>confidence</th>\n","      <th>class</th>\n","      <th>name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2012.078125</td>\n","      <td>958.723083</td>\n","      <td>2055.644287</td>\n","      <td>979.833557</td>\n","      <td>0.708333</td>\n","      <td>0</td>\n","      <td>Airplane</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2014.387695</td>\n","      <td>956.110901</td>\n","      <td>2051.807617</td>\n","      <td>981.800781</td>\n","      <td>0.625428</td>\n","      <td>1</td>\n","      <td>Helicopter</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f439de1c-f8c3-4f6c-9941-8e4a4b1f365e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f439de1c-f8c3-4f6c-9941-8e4a4b1f365e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f439de1c-f8c3-4f6c-9941-8e4a4b1f365e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          xmin        ymin         xmax        ymax  confidence  class  \\\n","0  2012.078125  958.723083  2055.644287  979.833557    0.708333      0   \n","1  2014.387695  956.110901  2051.807617  981.800781    0.625428      1   \n","\n","         name  \n","0    Airplane  \n","1  Helicopter  "]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/val.py --weights /content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp13/weights/best.pt /content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp9/weights/best.pt --img 1600 --data /content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/data/aot.yaml --augment"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"46aLWUK_7oUC","executionInfo":{"status":"ok","timestamp":1648628321661,"user_tz":-60,"elapsed":137728,"user":{"displayName":"Pratikgiri Goswami","userId":"09564737531169887586"}},"outputId":"4186284c-0754-48e7-af9c-f16e7cec7f53"},"id":"46aLWUK_7oUC","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/data/aot.yaml, weights=['/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp13/weights/best.pt', '/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp9/weights/best.pt'], batch_size=32, imgsz=1600, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=True, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=../runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 🚀 8b9537a torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Fusing layers... \n","Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n","Fusing layers... \n","Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n","Ensemble created with ['/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp13/weights/best.pt', '/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/runs/train/exp9/weights/best.pt']\n","\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'test.cache' images and labels... 266 found, 0 missing, 0 empty, 0 corrupt: 100% 266/266 [00:00<?, ?it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 9/9 [02:01<00:00, 13.53s/it]\n","                 all        266        532       0.98      0.504      0.515      0.266\n","            Airplane        266        106          1       0.99      0.995      0.477\n","          Helicopter        266        266      0.939      0.523      0.549      0.319\n","            Airborne        266        160          1          0   0.000875    0.00035\n","Speed: 7.1ms pre-process, 406.6ms inference, 2.0ms NMS per image at shape (32, 3, 1600, 1600)\n","Results saved to \u001b[1m../runs/val/exp5\u001b[0m\n"]}]},{"cell_type":"code","source":["# Inference\n","results = model(img, augment=True)  # TTA inference"],"metadata":{"id":"7gePYMXK9wQB","colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"status":"error","timestamp":1644427165921,"user_tz":0,"elapsed":15,"user":{"displayName":"Pratikgiri Goswami","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-IHdzfDW9q5vpHRDnZ3Wm7c4oMkfMa-KSwAOatQ=s64","userId":"09564737531169887586"}},"outputId":"39906544-b7bd-46bf-feea-9a29c16d042f"},"id":"7gePYMXK9wQB","execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-feea16997ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TTA inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/yolov5/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, imgs, size, augment, profile)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'image{i}'\u001b[0m  \u001b[0;31m# filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filename or uri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexif_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Final-Year-Project-AI/object-sense-avoid-ai/notebooks/testImages/15553341149037764548af6dc9c2d794ea683e9554a0e728ca3.png'"]}]},{"cell_type":"code","source":["# Print out the prediction\n","results.print()  \n","# results.save()  \n","\n","# Return the Tensorflow format\n","results.xyxy\n","\n","# Show the labeled image\n","results.show()\n","\n","# Return the prediction dataframe\n","results.pandas().xyxy"],"metadata":{"id":"nZGkr5EN9xoi"},"id":"nZGkr5EN9xoi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(\"./runs/detect/run/15553341149037764548af6dc9c2d794ea683e9554a0e728ca3.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"TOiPVF9y-iei","executionInfo":{"status":"ok","timestamp":1644426575839,"user_tz":0,"elapsed":176,"user":{"displayName":"Pratikgiri Goswami","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-IHdzfDW9q5vpHRDnZ3Wm7c4oMkfMa-KSwAOatQ=s64","userId":"09564737531169887586"}},"outputId":"741ebc7e-3379-4b53-806b-749f8eee14b5"},"id":"TOiPVF9y-iei","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/png":"./runs/detect/run/15553341149037764548af6dc9c2d794ea683e9554a0e728ca3.png","text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":44}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"Yolo_Data_Train.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}